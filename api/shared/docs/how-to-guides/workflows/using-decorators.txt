# Use Decorators

Advanced decorator patterns and best practices

---

## Overview

Bifrost uses decorators to define workflows:

- **@workflow** - Registers executable workflow (all options optional)
- **@tool** - Registers an AI agent tool (alias for `@workflow(is_tool=True)`)
- **@data_provider** - Provides dynamic options for dropdowns

Parameters are automatically derived from function signatures - no decorator needed.

## Minimal Workflow

The simplest workflow needs just a decorator and docstring:

```python
from bifrost import workflow

@workflow
async def send_email(recipient: str, subject: str, body: str = ""):
    """Send an email message."""
    await email_service.send(recipient, subject, body)
    return {"sent": True}
```

This automatically:
- Sets name to `"send_email"` (from function name)
- Sets description to `"Send an email message."` (from docstring)
- Extracts parameters with types and defaults from signature

## @workflow Advanced Options

### Scheduling Workflows

Run workflows automatically on a schedule:

```python
@workflow(schedule="0 2 * * *")  # Daily at 2 AM UTC
async def daily_cleanup():
    """Daily cleanup task."""
    await cleanup_old_records()
    return {"cleaned": True}
```

**Cron Expressions**:

- `0 9 * * *` - Daily at 9 AM
- `0 */6 * * *` - Every 6 hours
- `0 9 * * 1` - Every Monday at 9 AM
- `0 0 1 * *` - First day of month at midnight

Use UTC times for schedules to ensure consistency across timezones.

### HTTP Endpoints

Expose workflows as HTTP endpoints for webhooks:

```python
@workflow(
    endpoint_enabled=True,
    allowed_methods=["POST"],
    public_endpoint=True  # Skip authentication
)
async def process_webhook(payload: dict):
    """Process incoming webhook."""
    # Available at: POST /api/endpoints/process_webhook
    return {"status": "processed"}
```

  

**endpoint_enabled** (bool)
: Expose at `/api/endpoints/{name}` (default: False)

**allowed_methods** (list)
: HTTP methods allowed (default: `["POST"]`)

**public_endpoint** (bool)
: Skip authentication for webhooks (default: False)

**disable_global_key** (bool)
: Only workflow-specific keys work (default: False)

  
  

```python
# Authenticated endpoint (requires API key)
@workflow(
    endpoint_enabled=True,
    allowed_methods=["GET", "POST"]
)
async def sync_data():
    """Sync data endpoint."""
    pass

# Public webhook (no auth required)
@workflow(
    endpoint_enabled=True,
    public_endpoint=True
)
async def github_webhook(payload: dict):
    """Handle GitHub webhooks."""
    pass
```

  

### Retry Policies

Automatically retry failed workflows:

```python
@workflow(
    retry_policy={
        "max_attempts": 3,
        "backoff_seconds": 5
    }
)
async def api_call():
    """Call external API with retries."""
    # Will retry up to 3 times with 5 second delay
    pass
```

### Execution Modes

Execution mode is auto-selected based on `endpoint_enabled`:

```python
# Auto-selects sync (endpoint needs immediate response)
@workflow(endpoint_enabled=True)
async def quick_lookup(id: str):
    """Quick lookup endpoint."""
    pass

# Auto-selects async (background execution)
@workflow
async def bulk_import(csv_url: str):
    """Import data from CSV."""
    pass

# Explicit override when needed
@workflow(
    endpoint_enabled=True,
    execution_mode="async"  # Returns 202 + execution_id
)
async def long_webhook(payload: dict):
    """Webhook that triggers long process."""
    pass
```

## Parameter Inference

Parameters are automatically extracted from your function signature:

```python
@workflow
async def create_user(
    email: str,                # Required string
    name: str,                 # Required string
    department: str = "IT",    # Optional with default
    active: bool = True,       # Optional boolean
    tags: list | None = None   # Optional list
):
    """Create a new user."""
    pass
```

**Type mapping:**
- `str` → string input
- `int` → integer input
- `float` → decimal input
- `bool` → checkbox
- `dict` → JSON editor
- `list` → array input

**Labels** are auto-generated from parameter names:
- `first_name` → "First Name"
- `userEmail` → "User Email"

## Using Data Providers with Forms

Data providers supply dynamic dropdown options. Link them to form fields (not to workflows directly):

### Creating Data Providers

```python
from bifrost import data_provider

@data_provider
async def get_departments() -> list[dict]:
    """List all departments."""
    return [
        {"label": "Engineering", "value": "eng"},
        {"label": "Sales", "value": "sales"}
    ]

@data_provider
async def get_users_by_dept(department: str) -> list[dict]:
    """Get users filtered by department."""
    users = await fetch_users(department)
    return [{"label": u.name, "value": u.id} for u in users]
```

### Linking to Forms

In your form JSON, reference data providers by ID:

```json
{
  "name": "department",
  "type": "select",
  "label": "Department",
  "data_provider_id": "uuid-of-get-departments"
}
```

For cascading dropdowns, pass values between fields:

```json
{
  "name": "user",
  "type": "select",
  "label": "User",
  "data_provider_id": "uuid-of-get-users-by-dept",
  "data_provider_inputs": {
    "department": "{{department}}"
  }
}
```

See the [Cascading Dropdowns guide](/how-to-guides/forms/cascading-dropdowns) for details.

## @data_provider Patterns

### Caching Strategies

  
```python
@data_provider(cache_ttl_seconds=3600)  # Cache for 1 hour
async def get_departments() -> list[dict]:
    """List departments (expensive query, cache results)."""
    return await fetch_departments()
```
  

  
```python
@data_provider(cache_ttl_seconds=0)  # Never cache
async def get_current_tickets() -> list[dict]:
    """Current open tickets (always fetch latest)."""
    return await fetch_open_tickets()
```
  

### Options with Metadata

```python
@data_provider
async def get_licenses() -> list[dict]:
    """Available licenses."""
    return [
        {
            "label": "Microsoft 365 E3",
            "value": "SPE_E3",
            "metadata": {
                "group": "Microsoft",
                "available": 50
            }
        },
        {
            "label": "Microsoft 365 E5",
            "value": "SPE_E5",
            "metadata": {
                "group": "Microsoft",
                "available": 10
            }
        }
    ]
```

## Best Practices

- **Use Descriptive Function Names**: `create_user_in_m365` not `proc1`
- **Write Clear Docstrings**: They become the workflow description
- **Use Type Hints**: Required for parameter extraction
- **Set Appropriate Timeouts**: Match expected execution time (default: 1800s)
- **Cache Wisely**: Balance freshness vs. performance in data providers

## Common Pitfalls

### Missing Docstring

❌ **Wrong**
```python
@workflow
async def example():
    pass  # No description in UI!
```

✅ **Correct**
```python
@workflow
async def example():
    """Process example data."""
    pass
```

### Missing Type Hints

❌ **Wrong**
```python
@workflow
async def example(name, count):  # Parameters won't be extracted!
    """Example workflow."""
    pass
```

✅ **Correct**
```python
@workflow
async def example(name: str, count: int = 1):
    """Example workflow."""
    pass
```

### Sync Mode for Long Tasks

❌ **Wrong**
```python
@workflow(execution_mode="sync")
async def bulk_import(data: list):  # Will timeout
    """Import thousands of records."""
    pass
```

✅ **Correct**
```python
@workflow  # Auto-selects async
async def bulk_import(data: list):
    """Import thousands of records."""
    pass
```

## Next Steps

- [Error Handling](/how-to-guides/workflows/error-handling) - Handle errors gracefully
- [Writing Workflows](/how-to-guides/workflows/writing-workflows) - Complete workflow guide
- [SDK Reference](/sdk-reference/sdk/decorators) - Full decorator documentation